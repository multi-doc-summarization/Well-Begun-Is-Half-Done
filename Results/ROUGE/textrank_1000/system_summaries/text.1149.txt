r the experiment , subjectsthe researchers themselvesspent hours lying still inside a magnetic resonance imaging ( mri ) machine , watching two sets of movie trailers . newline_char during the first set , recorded brain activity was fed into a computer to program a " movie reconstruction algorithm , " which matched neural activity to what was taking place in the video . newline_char subjects then watched the same set of trailers as the algorithm pieced together a video based on brain activity recorded by the mri . newline_char " scientists have long been able to reconstruct static photos and images from reading brain patterns , but this is believed to be a first for reading a dynamic visual experience . newline_char " our natural visual experience is like watching a movie , " shinji nishimoto , lead author of the study , said in a statement . story_separator_special_tag researchers from uc berkeley were able to reconstruct youtube videos from viewers ' brain activity -- a feat that might one day offer a glimpse into our dreams , memories and even fantasies . newline_char " gallant 's coauthors acted as study subjects , watching youtube videos inside a magnetic resonance imaging machine for several hours at a time . newline_char the reconstructed videos are blurry because they layer all the youtube clips that matched the subject 's brain activity pattern . newline_char " if you can decode movies people saw , you might be able to decode things in the brain that are movie-like but have no real-world analog , like dreams , " gallant said . newline_char shinji nishimoto , a neuroscientist in gallant 's lab and the study 's lead author , said the results shed light on how the brain understands and processes visual experiences .
